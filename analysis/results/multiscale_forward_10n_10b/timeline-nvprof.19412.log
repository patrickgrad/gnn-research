==19412== NVPROF is profiling process 19412, command: python snap.py --data_dir ../data/ --graph dblp --maxepoch 2 --profile-epoch-list 1 --profile-batch-list 100-110 --prof-forward
==19412== Profiling application: python snap.py --data_dir ../data/ --graph dblp --maxepoch 2 --profile-epoch-list 1 --profile-batch-list 100-110 --prof-forward
==19412== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   69.70%  38.879ms       650  59.814us     800ns  463.78us  void kernelPointwiseApply2<CopyOp<float, float>, float, float, unsigned int, int=1, int=1>(OffsetInfo<float, float, float>, OffsetInfo<CopyOp<float, float>, float, unsigned int>, float, float)
                   16.53%  9.2185ms       420  21.948us  1.9840us  493.96us  sgemm_32x32x32_NN
                    5.56%  3.0998ms       250  12.399us  3.6160us  17.696us  maxwell_scudnn_128x32_relu_interior_nn
                    2.58%  1.4414ms       180  8.0070us  1.6640us  25.760us  sgemm_32x32x32_NN_vec
                    0.97%  540.29us       130  4.1560us  2.5920us  10.848us  void CatArrayBatchedCopy<float, unsigned int, int=3>(float*, CatArrInputTensor<float, unsigned int>*, OutputTensorSizeStride<unsigned int, unsigned int=4>, int, unsigned int)
                    0.89%  498.31us       120  4.1520us  2.7840us  7.0080us  void cudnn::detail::bn_fw_tr_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>(cudnnTensorStruct, float const *, cudnn::detail::bn_fw_tr_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float const , float, float, float*, float const *, float const *, float const *, float, float, cudnn::reduced_divisor, int, float*, cudnn::detail::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)
                    0.82%  455.62us       250  1.8220us  1.2800us  3.1370us  void add_tensor_kernel_v3<int=2, float, float, int=128, int=1, int=1, int=4, int=2>(cudnnTensorStruct, float*, cudnnTensorStruct, float const *, float, float)
                    0.76%  423.78us        15  28.251us  1.4720us  82.401us  void gemv2N_kernel_val<float, float, float, int=128, int=4, int=4, int=4, int=1>(float, float, cublasGemv2Params_v2<float, float, float>)
                    0.56%  311.14us       250  1.2440us     928ns  6.7840us  cudnn::maxwell::gemm::computeOffsetsKernel(cudnn::maxwell::gemm::ComputeOffsetsParams)
                    0.51%  285.54us       120  2.3790us  1.8560us  3.8730us  void CatArrayBatchedCopy<float, unsigned int, int=4>(float*, CatArrInputTensor<float, unsigned int>*, OutputTensorSizeStride<unsigned int, unsigned int=4>, int, unsigned int)
                    0.31%  175.71us       250     702ns     480ns  4.1920us  [CUDA memcpy HtoD]
                    0.25%  140.71us       120  1.1720us     992ns  7.6480us  void kernelPointwiseApply1<TensorAddConstantOp<long>, long, unsigned int, int=1>(OffsetInfo<TensorAddConstantOp<long>, long, unsigned int>, long, long)
                    0.25%  136.83us        10  13.683us  12.256us  15.712us  void gemv2N_kernel_val<float, float, float, int=128, int=8, int=4, int=4, int=1>(float, float, cublasGemv2Params_v2<float, float, float>)
                    0.21%  119.78us       120     998ns     896ns  1.2800us  void kernelPointwiseApply2<TensorMaxValueOp<float>, float, float, unsigned int, int=1, int=1>(OffsetInfo<TensorMaxValueOp<float>, float, unsigned int>, OffsetInfo<float, float, int=1>, float, float)
                    0.10%  56.673us        25  2.2660us  1.6000us  4.3840us  void gemv2N_kernel_val<float, float, float, int=128, int=32, int=4, int=4, int=1>(float, float, cublasGemv2Params_v2<float, float, float>)
      API calls:   99.60%  8.26758s      2660  3.1081ms  4.8340us  846.83ms  cudaLaunch
                    0.24%  19.945ms     27890     715ns     527ns  404.36us  cudaGetDevice
                    0.07%  6.1827ms      9250     668ns     545ns  16.921us  cudaSetDevice
                    0.02%  2.0419ms       250  8.1670us  6.7250us  24.674us  cudaMemcpyAsync
                    0.02%  1.8458ms     17880     103ns      70ns  16.248us  cudaSetupArgument
                    0.01%  1.0682ms       620  1.7220us  1.2810us  12.005us  cudaEventRecord
                    0.01%  709.66us       354  2.0040us     712ns  12.020us  cudaEventQuery
                    0.01%  527.38us      3540     148ns      69ns  8.3400us  cudaGetLastError
                    0.01%  463.93us      2660     174ns     105ns  9.8500us  cudaConfigureCall
                    0.00%  381.02us       250  1.5240us  1.3150us  10.894us  cudaEventCreateWithFlags
                    0.00%  344.89us       280  1.2310us     665ns  2.3910us  cudaEventDestroy
==19412== Generated result file: /home/adam/school/research/gnn/gnn-research/multiscalegnn/multiscalegnn/profile/2019_03_03__12_16_19/train-timeline.19412.nvprof
